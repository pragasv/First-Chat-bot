{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random \n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools\n",
    "# ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "lines_filepath = os.path.join(\"Dataset_chatbot\",\"data\",\"cornell movie-dialogs corpus\",\"movie_lines.txt\")\n",
    "conv_filepath = os.path.join(\"Dataset_chatbot\",\"data\",\"cornell movie-dialogs corpus\",\"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "#visualizatize some lines\n",
    "with open(lines_filepath,'r') as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split eacg line of the file into a dictionary of fields(lineID,characterID,movieID,character,txt)\n",
    "line_fields = [\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "lines = {}\n",
    "with open(lines_filepath,'r',encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \" )\n",
    "        lineobj = {}\n",
    "        for i,field in enumerate (line_fields):\n",
    "            lineobj[field] = values[i]\n",
    "        lines[lineobj['lineID']] = lineobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(lines.items())[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups fields of lines from 'loadlines into conversation based on \"movie_conversation.txt\"\n",
    "conv_fields = [\"characterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n",
    "conversations = []\n",
    "with open(conv_filepath,'r',encoding='iso-8859-1')as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        convobj = {}\n",
    "        for i,field in enumerate(conv_fields):\n",
    "            convobj[field] = values[i]\n",
    "        lineIds = eval(convobj[\"utteranceIDs\"])\n",
    "        #reassemble lines\n",
    "        convobj[\"lines\"] = []\n",
    "        for lineId in lineIds:\n",
    "            convobj[\"lines\"].append(lines[lineId])\n",
    "        conversations.append(convobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nested dictionary visualization\n",
    "#conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts pairs of sentences from conversations\n",
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    #iterate over all the lines of the conversation \n",
    "    for i in range(len(conversation[\"lines\"])-1):\n",
    "        inputline = conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetline = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "        #filter wrong samples (if one of the list is empty)\n",
    "        if inputline and targetline:\n",
    "            qa_pairs.append([inputline,targetline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question and answer pairs\n",
    "#qa_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing newly formatted data...\n",
      "done wirting to file\n"
     ]
    }
   ],
   "source": [
    "#define path to new file\n",
    "datafile = os.path.join(\"Dataset_chatbot\",\"data\",\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "delimiter = \"\\t\"\n",
    "#unescape the delimiter \n",
    "delimiter = str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "\n",
    "#write new csv file \n",
    "print(\"\\nwriting newly formatted data...\")\n",
    "with open(datafile,'w',encoding = \"utf-8\") as outputfile:\n",
    "    writer = csv.writer(outputfile,delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)\n",
    "    print(\"done wirting to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "#visualize some lines \n",
    "datafile = os.path.join(\"Dataset_chatbot\",\"data\",\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "with open(datafile,'rb') as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:2]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 #used for padding short sentences \n",
    "SOS_token = 1 # start of  sentance taken\n",
    "EOS_token = 2 #end of sentence taken\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token : \"PAD\",SOS_token : \"SOS\",EOS_token : \"EOS\"}\n",
    "        self.num_words = 3 #count sos,eos,pad\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    # increment count if the word exists else create a new stack\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] +=1\n",
    "            \n",
    "    #remove words below a certain count threshold (remove rare words)\n",
    "    def trim(self,min_count):\n",
    "        keep_words = []\n",
    "        # k - key(key) , v - value(threshold check)\n",
    "        for k,v in self.word2count.items():\n",
    "            if v>= min_count:\n",
    "                keep_words.append(k)\n",
    "        print('keep_words {} / {} '.format(len(keep_words),len(self.word2index)))\n",
    "        \n",
    "        #reinitialize dictionaries \n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 #count default tokens\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn a unicode to ascii \n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) !='Mn')\n",
    "\n",
    "#'Mn' - non marking space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'montreal,francoise...'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test for function \n",
    "unicodeToAscii('montreal,francoise...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase , trim white spaces, lines...etc and remove non letter characters \n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #replace any .!? by a white space as well as the character\n",
    "    s = re.sub(r\"([.!?])\",r\" \\1\",s)\n",
    "    #remove any character that is not a sequence of the lower or upper case letters\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\",r\" \",s)\n",
    "    #remove a sequence of white space characters \n",
    "    s = re.sub(r\"\\s+\",r\" \",s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa aa !s s dd ?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the function\n",
    "normalizeString(\"aa123aa!s's  DD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing files...please wait\n",
      "reading ...Done\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join(\"Dataset_chatbot\",\"data\",\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "#reading the file and split into lines \n",
    "print(\"reading and processing files...please wait\")\n",
    "lines = open(datafile,encoding='utf-8').read().strip().split('\\n')\n",
    "#split every line into pairs and normalize \n",
    "pairs = [[normalizeString(s) for s in pair.split('\\t')]for pair in lines]\n",
    "print(\"reading ...Done\")\n",
    "voc = Vocabulary(\"cornell movie-dialogs corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]\n",
      "\n",
      "\n",
      "total number of conversations : 442563\n"
     ]
    }
   ],
   "source": [
    "print(lines[0].split('\\t'))\n",
    "print('\\n')\n",
    "print(\"total number of conversations :\",len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns true if both sequences in pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 10 #max senntence length to consider\n",
    "def filterPair(p):\n",
    "    #input sequences need to preserve the last word for EOS taken\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return[pair for pair in pairs if filterPair(pair)]\n",
    "#remove the conversation from the database if teh length exceeds\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 221282 pairs/conversations in the dataset\n",
      "after filtering , there are 64271 pairs/conversations\n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair)>1]\n",
    "print(\"there are {} pairs/conversations in the dataset\".format(len(pairs)))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"after filtering , there are {} pairs/conversations\".format(len(pairs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted words: 18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "#loop through each pair and add the questions and reply sentence to the vocabulary\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"counted words:\",voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7823 / 18005 \n",
      "Trimmed from 64271 pairs to 58043,\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3  #minimum word count for trimming \n",
    "\n",
    "def trimRareWords(voc,pairs,MIN_OCUNT):\n",
    "    #trim words used under the MIN_OCUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    #filter out pairs with trimmed words \n",
    "    keep_pairs = []\n",
    "    for pair in pairs : \n",
    "        input_sentence = pair[0]\n",
    "        output_senence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        #check input sentence \n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        \n",
    "        #only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    \n",
    "    print('Trimmed from {} pairs to {},'.format(len(pairs), len(keep_pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "pairs = trimRareWords(voc,pairs,MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepairing the data for the model\n",
    "\n",
    "#number of rows will indicate the batch size\n",
    "#number of coloms will indicate the maximum length of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion from word to index\n",
    "def indexesFromSentence(voc,sentence):\n",
    "    #for word in sentence.split(' '):\n",
    "        #print (\"sentence is :\",sentence)\n",
    "        #print(\"word is :\",word)\n",
    "        #print(\"VOC word 2 index is:\", voc.word2index[word])\n",
    "        \n",
    "    try :\n",
    "        return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "        \n",
    "    except KeyError:\n",
    "        return [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have my word . as a gentleman\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the function \n",
    "print(pairs[1][0])\n",
    "indexesFromSentence(voc,pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'the real you .']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [53, 54, 7, 4, 2]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define some samples for testing \n",
    "inp = []\n",
    "out = []\n",
    "i = 0\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "print(inp)\n",
    "print(len(inp))\n",
    "indexes = [indexesFromSentence(voc,sentence) for sentence in inp]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to keep the colom length consistent , pad the rest with 0\n",
    "def zeroPadding(l, fillvalue =  0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng = [len(ind) for ind in indexes]\n",
    "max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 53),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 54),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 7),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 4),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 2),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the function\n",
    "test_result = zeroPadding(indexes)\n",
    "print(len(test_result))  #the max length is now the number of rows or the batch size\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l , value = 0):\n",
    "    m = []\n",
    "    for i , seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                 m[i].append(1)\n",
    "    return m                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_result = binaryMatrix(test_result)\n",
    "binary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns padded input sequence tensor and as well as a tensor of lengths for each of the sequence in the batch \n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns padded target sequence tensor, padding mask and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    #sort the question in decending length\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse = True)\n",
    "    input_batch, output_batch = [],[]\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    \n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input variable :\n",
      "tensor([[ 122,   25,    7,  464,   36],\n",
      "        [   7, 3513,   24, 5645,   37],\n",
      "        [  24,    7,    4,    7,  123],\n",
      "        [ 101,   40,   53,   89,   40],\n",
      "        [ 659,  400,   52,  534,  863],\n",
      "        [ 334,   45,   25,   12,   83],\n",
      "        [  67,  879,  882,  228,    6],\n",
      "        [   4,    4,    4,    4,    2],\n",
      "        [   2,    2,    2,    2,    0]])\n",
      "lengths : \n",
      "tensor([9, 9, 9, 9, 8])\n",
      "target_variable: \n",
      "tensor([[ 122,    7,   25, 2762,    3],\n",
      "        [3867, 3513, 3897,    4,    0],\n",
      "        [ 743,   83,   76,    4,    0],\n",
      "        [ 188,   40,  276,    4,    0],\n",
      "        [ 480,  547,   53,   51,    0],\n",
      "        [   4,    9, 2542,    4,    0],\n",
      "        [   2, 1948,    4,    2,    0],\n",
      "        [   0,    4,    2,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n",
      "mask : \n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len :  9\n"
     ]
    }
   ],
   "source": [
    "# example for validation \n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input variable :\")\n",
    "print(input_variable)\n",
    "print(\"lengths : \")\n",
    "print(lengths)\n",
    "print(\"target_variable: \")\n",
    "print(target_variable)\n",
    "print(\"mask : \")\n",
    "print(mask)\n",
    "print(\"max_target_len : \",max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - convert word indexes to embeddings\n",
    "# - pack padded batch of sequences for RNN module \n",
    "# forward pass through GRU\n",
    "# unpack padding\n",
    "#return the output and the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bi directional GRU used over here - to take advantage of the past and future\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers = 1, dropout = 0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        #initialize GRU ; input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout),bidirectional=True)\n",
    "    \n",
    "    def forward(self, input_seq, input_lengths, hidden =None):\n",
    "        # input_seq: batch of input sentences; shape = (max_length,batch_size)\n",
    "        # input_lengths : list of sentence lengths corresponding to each sentence in the batch\n",
    "        # hidden state, of shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "        # convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        #pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        #forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        #unpacked padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        #sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        #return output and final hidden state\n",
    "        return outputs , hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorder -  attention model (has an attention operation - layer)\n",
    "# the luong attentio layer has been implemented \n",
    "\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        #element wose miltiply the current target decorder state with the encorder output and sum\n",
    "        return torch.sum(hidden * encoder_output, dim = 2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        #hidden of shape (1, batch_size, hidden_size)\n",
    "        #encorder_outputs of shape : (max_length, batch_size, hidden_size)\n",
    "        \n",
    "        #calculate the attention weights (energies)\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs) #maxlength and batchsize\n",
    "        #transpose max length and batch size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "        #return the softmax normalized probability scores (with added dimensions)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #define layers \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout = (0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs): \n",
    "        #get embedded of the current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        #forward  through unidirectional GRU \n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        #calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        #multiply attention weights to encorder outputs to get the new \"weighted sum\" contect vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "        #conctenate weighted context vector and GRU outputs \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        #predict next word using luoung eq 6 \n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        #return output and the final hidden state\n",
    "        return output, hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_out, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    target = target.view(-1,1)\n",
    "    # decorder_out shape: (batch_size, vocab_size) , target_size =(batch_size,1)\n",
    "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
    "    #calculate the Negative log likelihood loss\n",
    "    crossEntropy = -torch.log(gathered_tensor)\n",
    "    #select the non zero elements\n",
    "    loss = crossEntropy.masked_select(mask)\n",
    "    #calculate the mean of the loss\n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1801, 0.0805, 0.1245, 0.1951, 0.1729, 0.0863, 0.1606],\n",
      "        [0.1784, 0.1260, 0.1122, 0.1196, 0.1385, 0.1506, 0.1747],\n",
      "        [0.1593, 0.1629, 0.1656, 0.1712, 0.0829, 0.1087, 0.1494],\n",
      "        [0.1061, 0.1920, 0.0971, 0.2278, 0.1388, 0.0962, 0.1420],\n",
      "        [0.1709, 0.1873, 0.1938, 0.1144, 0.0903, 0.1311, 0.1121]])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [4],\n",
      "        [0]])\n",
      "tensor([[0.1245],\n",
      "        [0.1260],\n",
      "        [0.1087],\n",
      "        [0.1388],\n",
      "        [0.1709]])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "#visualization of the performance of the loss function \n",
    "\n",
    "dec_o = torch.rand(5,7)\n",
    "dec_o = F.softmax(dec_o, dim=1)\n",
    "tar = torch.tensor([2, 1, 5, 4,0], dtype = torch.long)\n",
    "tar = tar.view(-1,1)\n",
    "mask = torch.tensor([1,0,1,1,0], dtype = torch.uint8)\n",
    "print(dec_o)\n",
    "print(tar)\n",
    "gath_ten = torch.gather(dec_o, 1, tar)\n",
    "print(gath_ten)\n",
    "print(gath_ten.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher forced training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are supplying the inputs regardless the last word generated - dsnt mimic real life situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input variable shape: torch.Size([10, 5])\n",
      "lengths shape: torch.Size([5])\n",
      "target_variable shape : torch.Size([10, 5])\n",
      "mask shape : torch.Size([10, 5])\n",
      "max_target_len: 10\n",
      "encoder outputs Shape: torch.Size([10, 5, 500])\n",
      "last encoder hidden shape: torch.Size([4, 5, 500])\n",
      "initial decoder hidden state shape: torch.Size([2, 5, 500])\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([  86, 7696,  197,   25,    3])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9326, grad_fn=<MeanBackward0>)\n",
      "Total : 5\n",
      "5\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([ 25,  66, 117, 200,   0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9209, grad_fn=<MeanBackward0>)\n",
      "Total : 4\n",
      "9\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([ 63, 158,   7, 169,   0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9421, grad_fn=<MeanBackward0>)\n",
      "Total : 4\n",
      "13\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([  4,  96, 393,   7,   0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9646, grad_fn=<MeanBackward0>)\n",
      "Total : 4\n",
      "17\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([   2,   53,   50, 1948,    0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9137, grad_fn=<MeanBackward0>)\n",
      "Total : 4\n",
      "21\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([   0,  705,   65, 3392,    0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9569, grad_fn=<MeanBackward0>)\n",
      "Total : 3\n",
      "24\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([   0,   66, 1075,    4,    0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9452, grad_fn=<MeanBackward0>)\n",
      "Total : 3\n",
      "27\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([0, 2, 7, 2, 0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9336, grad_fn=<MeanBackward0>)\n",
      "Total : 3\n",
      "30\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([0, 0, 6, 0, 0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9394, grad_fn=<MeanBackward0>)\n",
      "Total : 1\n",
      "31\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n",
      "decoder output shape : torch.Size([5, 7826])\n",
      "decoder hidden shape : torch.Size([2, 5, 500])\n",
      "the target variable at the current timestep before time shaping : tensor([0, 0, 2, 0, 0])\n",
      "the target variable at the current timestep shape before reshaping : torch.Size([5])\n",
      "the decoder input shape : torch.Size([1, 5])\n",
      "the mask at the current timestep : tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "the mask at the current time step shape : torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask loss : tensor(8.9072, grad_fn=<MeanBackward0>)\n",
      "Total : 1\n",
      "32\n",
      "returned loss: 0.0\n",
      "\n",
      "\n",
      "-----------DONE ONE TIME---------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualize whats happening in one iteration. \n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input variable shape:\",input_variable.shape)\n",
    "print(\"lengths shape:\",lengths.shape)\n",
    "print(\"target_variable shape :\", target_variable.shape)\n",
    "print(\"mask shape :\", mask.shape)\n",
    "print(\"max_target_len:\",max_target_len)\n",
    "\n",
    "#define parameters\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2 \n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "attn_model = 'dot'\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "#define the encoder and decoder\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "#ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "#initialize optimizers \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr =0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr =0.001)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0\n",
    "print_losses = []\n",
    "n_totals = 0\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"encoder outputs Shape:\", encoder_outputs.shape)\n",
    "print(\"last encoder hidden shape:\",encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "\n",
    "#set initial decoder hidden state to encoders final hidden state\n",
    "decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "print(\"initial decoder hidden state shape:\",decoder_hidden.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#assume we are using teacher forcing\n",
    "for t in range(max_target_len):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    print(\"decoder output shape :\", decoder_output.shape)\n",
    "    print(\"decoder hidden shape :\", decoder_hidden.shape)\n",
    "    \n",
    "    #teacher forcing \n",
    "    decoder_input = target_variable[t].view(1,-1)\n",
    "    print(\"the target variable at the current timestep before time shaping :\", target_variable[t])\n",
    "    print(\"the target variable at the current timestep shape before reshaping :\",target_variable[t].shape)\n",
    "    print(\"the decoder input shape :\",decoder_input.shape)\n",
    "    \n",
    "    #calculate and accumlate loss \n",
    "    print(\"the mask at the current timestep :\",mask[t])\n",
    "    print(\"the mask at the current time step shape :\",mask[t].shape)\n",
    "    mask_loss , nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "    print(\"mask loss :\",mask_loss)\n",
    "    print(\"Total :\",nTotal)\n",
    "    n_totals += nTotal\n",
    "    print(n_totals)\n",
    "    #update the weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    returned_loss = sum(print_losses) / n_totals\n",
    "    print(\"returned loss:\",returned_loss)\n",
    "    print(\"\\n\")\n",
    "    print(\"-----------DONE ONE TIME---------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off the teacher enforcing to train data \n",
    "# the same code but target would be the top prediction\n",
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "    \n",
    "    \n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"Dataset_chatbot\",\"data\", \"save\")\n",
    "corpus_name = \"cornell movie-dialogs corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 0.0%; Average loss: 8.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2; Percent complete: 0.1%; Average loss: 8.7529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3; Percent complete: 0.1%; Average loss: 8.4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4; Percent complete: 0.1%; Average loss: 7.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5; Percent complete: 0.1%; Average loss: 7.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:67: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:54: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6; Percent complete: 0.1%; Average loss: 6.4443\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
